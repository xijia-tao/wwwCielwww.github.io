<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='The post gives some keypoints on the course content of COMP3270 Artificial Intelligence @HKU, 2021-22 semester 2. It can be used as a directional material for those who are interested in (the more traditional side of) AI, or for revision purposes to future attendants of this course.
Search  uninformed search (BFS, DFS, UCS) informed search (greedy, A*)  A* TSA is optimal iff admissible A* GSA is optimal iff consistent (which implies admissible) consistency: h(a) - h(c) &amp;lt;= cost(a to c) / f value (sum) along a path never decreases   local search  cost of neighboring states (randomly) find local minimum   constraint satisfaction - csp  backtracking search (DFS, 1 variable at a time, only legal assignments at each point) improvements  forward checking (cross off values given the current config) constraint propagation ac-3 (repeatedly enforce, arc consistency iff some valid y in head for all x in tail) variable ordering (mrv -&amp;gt; min remaining values; most degree ~ tie-breaker) value ordering (lcv -&amp;gt; least constraining value, rules out the fewest )     adversarial search (minimax, dls, utility)  horizon effect: unavoidable damage with a low depth limit, delay -&amp;gt; more damage $\alpha-\beta$ pruning:  $\alpha:=$ best explored option along path to root for max initialize $\alpha=-\infty, \beta=\infty$ max value function: is terminal -&amp;gt; return utility value for each action, v = max(v, min-value(s&#39;, alpha, beta)) if $v\geq\beta$, then return $v$ alpha=max(alpha, v) finally return $v$   expectimax: replace min nodes with chance nodes by computing the weighted average of children expectiminimax: environment is an extra random agent that moves after each min/max agent    MDP  MDP: S, A, T(s, a, s&amp;rsquo;) = P(s&amp;rsquo; \mid s, a), R(s, a, s&amp;rsquo;), s0, optional terminal state stationarity (sequences with the same start state have the same order without it) implies only two ways to assign utilities to sequences  additive rewards discounted rewards   $V(s), Q(s, a), \pi(s)$ time-limited values save computation for no / unreachable terminal states value iteration: $V_{k&#43;1}(s)\leftarrow \max_a\sum_{s&amp;rsquo;}T(s, a, s&amp;rsquo;)[R(s, a, s&amp;rsquo;)&#43;\gamma V_{k}(s&amp;rsquo;)]$ with $V_0=0$, repeat until convergence  slow: $O(S^2A)$ per iteration policy converges long before values   policy iteration: do several passes that update utilities with fixed policy; a new policy is chosen with one-step lookahead (like policy extraction) policy evaluation: utilities for a fixed policy $V^\pi(s)=\sum_{s&amp;rsquo;}T(s, \pi(s), s&amp;rsquo;)[R(s, \pi, s&amp;rsquo;) &#43; \gamma V^\pi(s&amp;rsquo;)]$ (use method similar to value iteration as above / use linear solver since max is gone) policy extraction: (mini-)expectimax on V*, i.'><title>COMP3270 Artificial Intelligence Course Notes</title>

<link rel='canonical' href='https://wwwCielwww.github.io/p/comp3270/'>

<link rel="stylesheet" href="/scss/style.min.8e3bed18845372cf7933650cadff28b06d98007acbe7f356a2a501f2aa954ff0.css"><meta property='og:title' content='COMP3270 Artificial Intelligence Course Notes'>
<meta property='og:description' content='The post gives some keypoints on the course content of COMP3270 Artificial Intelligence @HKU, 2021-22 semester 2. It can be used as a directional material for those who are interested in (the more traditional side of) AI, or for revision purposes to future attendants of this course.
Search  uninformed search (BFS, DFS, UCS) informed search (greedy, A*)  A* TSA is optimal iff admissible A* GSA is optimal iff consistent (which implies admissible) consistency: h(a) - h(c) &amp;lt;= cost(a to c) / f value (sum) along a path never decreases   local search  cost of neighboring states (randomly) find local minimum   constraint satisfaction - csp  backtracking search (DFS, 1 variable at a time, only legal assignments at each point) improvements  forward checking (cross off values given the current config) constraint propagation ac-3 (repeatedly enforce, arc consistency iff some valid y in head for all x in tail) variable ordering (mrv -&amp;gt; min remaining values; most degree ~ tie-breaker) value ordering (lcv -&amp;gt; least constraining value, rules out the fewest )     adversarial search (minimax, dls, utility)  horizon effect: unavoidable damage with a low depth limit, delay -&amp;gt; more damage $\alpha-\beta$ pruning:  $\alpha:=$ best explored option along path to root for max initialize $\alpha=-\infty, \beta=\infty$ max value function: is terminal -&amp;gt; return utility value for each action, v = max(v, min-value(s&#39;, alpha, beta)) if $v\geq\beta$, then return $v$ alpha=max(alpha, v) finally return $v$   expectimax: replace min nodes with chance nodes by computing the weighted average of children expectiminimax: environment is an extra random agent that moves after each min/max agent    MDP  MDP: S, A, T(s, a, s&amp;rsquo;) = P(s&amp;rsquo; \mid s, a), R(s, a, s&amp;rsquo;), s0, optional terminal state stationarity (sequences with the same start state have the same order without it) implies only two ways to assign utilities to sequences  additive rewards discounted rewards   $V(s), Q(s, a), \pi(s)$ time-limited values save computation for no / unreachable terminal states value iteration: $V_{k&#43;1}(s)\leftarrow \max_a\sum_{s&amp;rsquo;}T(s, a, s&amp;rsquo;)[R(s, a, s&amp;rsquo;)&#43;\gamma V_{k}(s&amp;rsquo;)]$ with $V_0=0$, repeat until convergence  slow: $O(S^2A)$ per iteration policy converges long before values   policy iteration: do several passes that update utilities with fixed policy; a new policy is chosen with one-step lookahead (like policy extraction) policy evaluation: utilities for a fixed policy $V^\pi(s)=\sum_{s&amp;rsquo;}T(s, \pi(s), s&amp;rsquo;)[R(s, \pi, s&amp;rsquo;) &#43; \gamma V^\pi(s&amp;rsquo;)]$ (use method similar to value iteration as above / use linear solver since max is gone) policy extraction: (mini-)expectimax on V*, i.'>
<meta property='og:url' content='https://wwwCielwww.github.io/p/comp3270/'>
<meta property='og:site_name' content='Ciel&#39;s blog website &lt;3'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2022-05-11T00:00:00&#43;00:00'/><meta property='article:modified_time' content='2022-05-11T00:00:00&#43;00:00'/>
<meta name="twitter:title" content="COMP3270 Artificial Intelligence Course Notes">
<meta name="twitter:description" content="The post gives some keypoints on the course content of COMP3270 Artificial Intelligence @HKU, 2021-22 semester 2. It can be used as a directional material for those who are interested in (the more traditional side of) AI, or for revision purposes to future attendants of this course.
Search  uninformed search (BFS, DFS, UCS) informed search (greedy, A*)  A* TSA is optimal iff admissible A* GSA is optimal iff consistent (which implies admissible) consistency: h(a) - h(c) &amp;lt;= cost(a to c) / f value (sum) along a path never decreases   local search  cost of neighboring states (randomly) find local minimum   constraint satisfaction - csp  backtracking search (DFS, 1 variable at a time, only legal assignments at each point) improvements  forward checking (cross off values given the current config) constraint propagation ac-3 (repeatedly enforce, arc consistency iff some valid y in head for all x in tail) variable ordering (mrv -&amp;gt; min remaining values; most degree ~ tie-breaker) value ordering (lcv -&amp;gt; least constraining value, rules out the fewest )     adversarial search (minimax, dls, utility)  horizon effect: unavoidable damage with a low depth limit, delay -&amp;gt; more damage $\alpha-\beta$ pruning:  $\alpha:=$ best explored option along path to root for max initialize $\alpha=-\infty, \beta=\infty$ max value function: is terminal -&amp;gt; return utility value for each action, v = max(v, min-value(s&#39;, alpha, beta)) if $v\geq\beta$, then return $v$ alpha=max(alpha, v) finally return $v$   expectimax: replace min nodes with chance nodes by computing the weighted average of children expectiminimax: environment is an extra random agent that moves after each min/max agent    MDP  MDP: S, A, T(s, a, s&amp;rsquo;) = P(s&amp;rsquo; \mid s, a), R(s, a, s&amp;rsquo;), s0, optional terminal state stationarity (sequences with the same start state have the same order without it) implies only two ways to assign utilities to sequences  additive rewards discounted rewards   $V(s), Q(s, a), \pi(s)$ time-limited values save computation for no / unreachable terminal states value iteration: $V_{k&#43;1}(s)\leftarrow \max_a\sum_{s&amp;rsquo;}T(s, a, s&amp;rsquo;)[R(s, a, s&amp;rsquo;)&#43;\gamma V_{k}(s&amp;rsquo;)]$ with $V_0=0$, repeat until convergence  slow: $O(S^2A)$ per iteration policy converges long before values   policy iteration: do several passes that update utilities with fixed policy; a new policy is chosen with one-step lookahead (like policy extraction) policy evaluation: utilities for a fixed policy $V^\pi(s)=\sum_{s&amp;rsquo;}T(s, \pi(s), s&amp;rsquo;)[R(s, \pi, s&amp;rsquo;) &#43; \gamma V^\pi(s&amp;rsquo;)]$ (use method similar to value iteration as above / use linear solver since max is gone) policy extraction: (mini-)expectimax on V*, i.">
    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu26fd8464577ab2cf0412db6fc5fa2810_806527_300x0_resize_q75_box.jpg" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">🍥</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Ciel&#39;s blog website &lt;3</a></h1>
            <h2 class="site-description">Lorem ipsum dolor sit amet, consectetur adipiscing elit.</h2>
        </div>
    </header><ol class="social-menu">
            
                <li>
                    <a 
                        href='https://github.com/wwwCielwww'
                        target="_blank"
                        title="GitHub"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        

        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        

        <li >
            <a href='/content/page/about/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>About</span>
            </a>
        </li>
        
        

        <li >
            <a href='/content/page/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        

        <li >
            <a href='/content/page/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        

        <li >
            <a href='/content/page/links/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>Links</span>
            </a>
        </li>
        

        <div class="menu-bottom-section">
                <li id="i18n-switch">  
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M4 5h7" />
  <path d="M9 3v2c0 4.418 -2.239 8 -5 8" />
  <path d="M5 9c-.003 2.144 2.952 3.908 6.7 4" />
  <path d="M12 20l4 -9l4 9" />
  <path d="M19.1 18h-6.2" />
</svg>



                    <select name="language" onchange="window.location.href = this.selectedOptions[0].value">
                        
                            <option value="https://wwwCielwww.github.io/" selected>English</option>
                        
                            <option value="https://wwwCielwww.github.io/zh-cn/" >中文</option>
                        
                            <option value="https://wwwCielwww.github.io/ar/" >عربي</option>
                        
                    </select>
                </li>
            
            
            
                <li id="dark-mode-toggle">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                    <span>Dark Mode</span>
                </li>
            
        </div>
    </ol>
</aside>
<main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/course-notes/" >
                Course Notes
            </a>
        
            <a href="/categories/artificial-intelligence/" >
                Artificial Intelligence
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/comp3270/">COMP3270 Artificial Intelligence Course Notes</a>
        </h2>
    
        
    </div>

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">May 11, 2022</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    4 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>
</header>

    <section class="article-content">
    
    
    <p>The post gives some keypoints on the course content of COMP3270 Artificial Intelligence @HKU, 2021-22 semester 2. It can be used as a directional material for those who are interested in (the more traditional side of) AI, or for revision purposes to future attendants of this course.</p>
<h2 id="search">Search</h2>
<ol>
<li>uninformed search (BFS, DFS, UCS)</li>
<li>informed search (greedy, A*)
<ul>
<li>A* TSA is optimal iff admissible</li>
<li>A* GSA is optimal iff consistent (which implies admissible)</li>
<li>consistency: h(a) - h(c) &lt;= cost(a to c) / f value (sum) along a path never decreases</li>
</ul>
</li>
<li>local search
<ul>
<li>cost of neighboring states (randomly)</li>
<li>find local minimum</li>
</ul>
</li>
<li>constraint satisfaction - csp
<ul>
<li>backtracking search (DFS, 1 variable at a time, only legal assignments at each point)</li>
<li>improvements
<ul>
<li>forward checking (cross off values given the current config)</li>
<li>constraint propagation ac-3 (repeatedly enforce, arc consistency iff some valid y in head for all x in tail)</li>
<li>variable ordering (mrv -&gt; min remaining values; most degree ~ tie-breaker)</li>
<li>value ordering (lcv -&gt; least constraining value, rules out the fewest )</li>
</ul>
</li>
</ul>
</li>
<li>adversarial search (minimax, dls, utility)
<ul>
<li>horizon effect: unavoidable damage with a low depth limit, delay -&gt; more damage</li>
<li>$\alpha-\beta$ pruning:
<ul>
<li>$\alpha:=$ best explored option along path to root for max</li>
<li>initialize $\alpha=-\infty, \beta=\infty$</li>
<li>max value function: is terminal -&gt; return utility value</li>
<li>for each action, <code>v = max(v, min-value(s', alpha, beta))</code></li>
<li>if $v\geq\beta$, then return $v$</li>
<li><code>alpha=max(alpha, v)</code></li>
<li>finally return $v$</li>
</ul>
</li>
<li>expectimax: replace min nodes with chance nodes by computing the weighted average of children</li>
<li>expectiminimax: environment is an extra random agent that moves after each min/max agent</li>
</ul>
</li>
</ol>
<h2 id="mdp">MDP</h2>
<ol>
<li>MDP: S, A, T(s, a, s&rsquo;) = P(s&rsquo; \mid  s, a), R(s, a, s&rsquo;), s0, optional terminal state</li>
<li>stationarity (sequences with the same start state have the same order without it) implies only two ways to assign utilities to sequences
<ul>
<li>additive rewards</li>
<li>discounted rewards</li>
</ul>
</li>
<li>$V(s), Q(s, a), \pi(s)$</li>
<li>time-limited values save computation for no / unreachable terminal states</li>
<li>value iteration: $V_{k+1}(s)\leftarrow \max_a\sum_{s&rsquo;}T(s, a, s&rsquo;)[R(s, a, s&rsquo;)+\gamma V_{k}(s&rsquo;)]$ with $V_0=0$, repeat until convergence
<ul>
<li>slow: $O(S^2A)$ per iteration</li>
<li>policy converges long before values</li>
</ul>
</li>
<li>policy iteration: do several passes that update utilities with fixed policy; a new policy is chosen with one-step lookahead (like policy extraction)</li>
<li>policy evaluation: utilities for a fixed policy $V^\pi(s)=\sum_{s&rsquo;}T(s, \pi(s), s&rsquo;)[R(s, \pi, s&rsquo;) + \gamma V^\pi(s&rsquo;)]$ (use method similar to value iteration as above / use linear solver since max is gone)</li>
<li>policy extraction: (mini-)expectimax on V*, i.e. one-step lookahead / directly from Q</li>
</ol>
<h2 id="rl">RL</h2>
<ol>
<li>TD-learning
<ul>
<li>sample = $R(s,\pi(s), s&rsquo;)+\gamma V^\pi(s&rsquo;)$</li>
<li>update: $V^\pi(s)\leftarrow (1-\alpha)V^\pi(s)+\alpha[\text{sample}]$</li>
</ul>
</li>
<li>Q-learning
<ul>
<li>sample = $R(s,a,s&rsquo;)+\gamma\max_{a&rsquo;}Q(s&rsquo;,a&rsquo;)$</li>
<li>update: $Q(s,a)\leftarrow (1-\alpha)Q(s,a)+\alpha[\text{sample}]$</li>
</ul>
</li>
<li>exploration function
<ul>
<li>epsilon-greedy: explore a fixed amount</li>
<li>explore areas whose badness is not (yet) established, eventually stop exploring</li>
<li>$f(u,n)=u+k/n$</li>
<li>$Q(s,a)\leftarrow R(s,a,s&rsquo;)+\gamma\max_{a&rsquo;}f(Q(s&rsquo;,a&rsquo;),N(s&rsquo;,a&rsquo;))$</li>
<li>propagate bonus back to states that lead to unknown states</li>
<li>minimize regret (difference between rewards and optimal rewards)</li>
</ul>
</li>
<li>approximate Q-learning
<ul>
<li>weights $w_i$ and features $f_i$, linear combination</li>
<li>difference = $[r+\gamma\max_{a&rsquo;}Q(s&rsquo;,a&rsquo;)]-Q(s,a)$</li>
<li>update: $w_i\leftarrow w_i+\alpha[\text{difference}]f_i(s,a)$</li>
<li>pro: experience is summed up in a few powerful numbers</li>
<li>con: states may share features but actually be very different in value</li>
</ul>
</li>
</ol>
<h2 id="mm">MM</h2>
<ol>
<li>mini-forward algorithm: time t-1 to t</li>
<li>stationary distributions $P_\infty(X)$</li>
</ol>
<h2 id="hmm">HMM</h2>
<ol>
<li>definition
<ul>
<li>initial distribution $P(X_1)$</li>
<li>transitions $P(X_t \mid  X_{t-1})$</li>
<li>emissions $P(E_t \mid  X_t)$</li>
</ul>
</li>
<li>belief state $B_t(X)=P(X_t\mid e_1,\dots,e_t)=P(X_t\mid e_{1:t})$
<ul>
<li>passage of time: $B&rsquo;(X_{t+1}):=P(X_{t+1}\mid e_{i:t})=\sum_{x_t}P(X_{t+1}\mid x_t)B(x_t)$</li>
<li>$B(X_{t+1})\propto P(e_{t+1}\mid X_{t+1})B&rsquo;(X_{t+1})$</li>
<li>then renormalize $\to$ beliefs reweighted by likelihood of evidence</li>
</ul>
</li>
<li>particle filtering
<ul>
<li>comes in when the dimension of X too big to use exact inference (e.g. continuous)</li>
<li>elapse time: $x&rsquo;=\text{sample}(P(X&rsquo;\mid x))$</li>
<li>observe: $w(x)=P(e\mid x),\ B(x)\propto P(e\mid x)B&rsquo;(X)$ then renormalize</li>
<li>resample: select prior samples in proportion to their likelihood</li>
</ul>
</li>
<li>forward algorithm (sum of paths)
<ul>
<li>$f_t[x_t]=P(x_t,e_{1:t})=P(e_t\mid x_t)\sum_{x_{t-1}}P(x_t\mid x_{t-1})f_{t-1}[x_{t-1}]$</li>
<li>get most likely explanation by taking argmax over $x_t$</li>
</ul>
</li>
<li>Viterbi algorithm (best path)
<ul>
<li>take max instead of sum</li>
</ul>
</li>
</ol>
<h2 id="bayes-nets">Bayes Nets</h2>
<ol>
<li>conditional independence: d-separation<img src="/p/comp3270/d-sep.png"
	width="1391"
	height="747"
	srcset="/p/comp3270/d-sep_hue99864bf8bedf15fec96970e91ab330d_103777_480x0_resize_box_3.png 480w, /p/comp3270/d-sep_hue99864bf8bedf15fec96970e91ab330d_103777_1024x0_resize_box_3.png 1024w"
	loading="lazy"
	
	
		class="gallery-image" 
		data-flex-grow="186"
		data-flex-basis="446px"
	
></li>
</ol>
<h2 id="nlp">NLP</h2>
<ol>
<li>word2vec
<ul>
<li>iterate through every word of the whole corpus</li>
<li>predict surrounding words using word vectors
<ul>
<li>$P(o\mid c)=\frac{\exp(u^T_ov_c)}{\sum_{w\in V}\exp(u_w^Tv_c)}$</li>
<li>$J(\theta)$ cost function, a sum of negative log probabilities</li>
</ul>
</li>
</ul>
</li>
<li>gradient descent: update all $\theta$ using all windows</li>
<li>stochastic gradient descent
<ul>
<li>repeatedly sample windows, and update after each one</li>
<li>$\nabla J(\theta)\in \mathbb{R}^{2dV}$ is sparse (2dV as every word can appear as a center or context word)</li>
<li>update at most 2m+1 word vectors</li>
</ul>
</li>
</ol>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.css"integrity="sha384-RZU/ijkSsFbcmivfdRBQDtwuwVqK7GMOw6IMvKyeWL2K5UAlyp6WonmB8m7Jd0Hn"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/katex.min.js"integrity="sha384-pK1WpvzWVBQiP0/GjnvRxV4mOb0oxFuyRxJlk6vVw146n3egcN5C925NCP7a7BY8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.13.13/dist/contrib/auto-render.min.js"integrity="sha384-vZTG03m&#43;2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.querySelector(`.article-content`), {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });})
</script>
    
</article>

    

    

<aside class="related-contents--wrapper">
    <h2 class="section-title">Related contents</h2>
    <div class="related-contents">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/content/post/comp3270/">
        
        

        <div class="article-details">
            <h2 class="article-title">COMP3270 Artificial Intelligence Course Notes</h2>
        </div>
    </a>
</article>
            
                
<article class="">
    <a href="/p/comp3360/">
        
        

        <div class="article-details">
            <h2 class="article-title">COMP3360 Computer Animation Course Notes</h2>
        </div>
    </a>
</article>
            
                
<article class="">
    <a href="/content/post/comp3360/">
        
        

        <div class="article-details">
            <h2 class="article-title">COMP3360 Computer Animation Course Notes</h2>
        </div>
    </a>
</article>
            
                
<article class="">
    <a href="/content/post/comp2120/">
        
        

        <div class="article-details">
            <h2 class="article-title">COMP2120 Computer Organization Course Notes</h2>
        </div>
    </a>
</article>
            
                
<article class="">
    <a href="/p/comp2120/">
        
        

        <div class="article-details">
            <h2 class="article-title">COMP2120 Computer Organization Course Notes</h2>
        </div>
    </a>
</article>
            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2022 Ciel&#39;s blog website &lt;3
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.11.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#search">Search</a></li>
    <li><a href="#mdp">MDP</a></li>
    <li><a href="#rl">RL</a></li>
    <li><a href="#mm">MM</a></li>
    <li><a href="#hmm">HMM</a></li>
    <li><a href="#bayes-nets">Bayes Nets</a></li>
    <li><a href="#nlp">NLP</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
