<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Animation on Ciel&#39;s blog website &lt;3</title>
        <link>https://wwwCielwww.github.io/tags/animation/</link>
        <description>Recent content in Animation on Ciel&#39;s blog website &lt;3</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 16 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://wwwCielwww.github.io/tags/animation/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>COMP3360 Computer Animation Course Notes</title>
        <link>https://wwwCielwww.github.io/p/comp3360/</link>
        <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
        
        <guid>https://wwwCielwww.github.io/p/comp3360/</guid>
        <description>&lt;p&gt;The post gives some keypoints on the course content of COMP3360 Computer Animation @HKU, 2021-22 semester 2. Since I wrote it as the cheat sheet for attending the final exam, some abbreviations for words (both technical and non-technical) were used, which might not be clear. You can also expect some strange formatting.&lt;/p&gt;
&lt;p&gt;Due to the limited time for exam preparation, I did not include the part on implicit integration and the second part of data-driven facial animation. I may (or may not) add them in the future as a separate note and attach the url here.&lt;/p&gt;
&lt;h1 id=&#34;comp3360-notes&#34;&gt;COMP3360 Notes&lt;/h1&gt;
&lt;h2 id=&#34;basics-of-computer-animation&#34;&gt;Basics of Computer Animation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;joints (translational - 1,2,3; hinge - knee, 1; universal - wrist, 2; rotational - shoulder, hip, neck)
&lt;ul&gt;
&lt;li&gt;2 ways to represent 3D rotations: gimbal (3 motors, euler angle) &amp;amp; free joint&lt;/li&gt;
&lt;li&gt;gimbal lock: e.g. order = x-y-z, rotate y for 90 deg, same x &amp;amp; z axis, 1 dof lost&lt;/li&gt;
&lt;li&gt;free: ball joint, rotation by angle $\alpha$ around axis a $(a_xS\frac{\alpha}{2},a_yS\frac{\alpha}{2},a_zS\frac{\alpha}{2},C\frac{\alpha}{2})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;generalized coordinates = (root location, root orientation, joint angles)&lt;/li&gt;
&lt;li&gt;homo coord trans: 4d matrix, LHS mul $\to$ world space, RHS $\to$ local space&lt;/li&gt;
&lt;li&gt;f kinematics: joint angles $\to$ position and orientation (of the end effector); ik&lt;/li&gt;
&lt;li&gt;interpolation: linear; high-order polynomial e.g. bezier - 2 end points, 2 control points for tangent vector
&lt;ul&gt;
&lt;li&gt;slerp for quaternions, $\theta=\arccos(q_1\cdot q_2), c_1=\frac{\sin\theta(1-t)}{\sin\theta}, c_2=\frac{\sin\theta t}{\sin\theta}$&lt;/li&gt;
&lt;li&gt;problems: constraints may not satisfied, error-propagation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;solution: ik - 3 approaches: analytical,
&lt;ul&gt;
&lt;li&gt;cyclic-coord descent: move up the hierarchy and move the next joint to min the distance between the end effector and the target; repeat until the ee reaches the target or max iterations reached (in case unreachable target) &lt;em&gt;may have oscillation problems&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;pseudo-inverse: &lt;em&gt;any topo structure, multiple constraints, incorporate physics&lt;/em&gt;
&lt;ul&gt;
&lt;li&gt;for small movements, linear $\Delta e=J\Delta q$&lt;/li&gt;
&lt;li&gt;pseudo inverse $J^+=(J^TJ)^{-1}J^T,\ \Delta q=J^+\Delta e$ (derived from lagrange multiplier)&lt;/li&gt;
&lt;li&gt;iteratively update the generalized coord so that position constraints are satisfied&lt;/li&gt;
&lt;li&gt;singularity problem: unreachable posture when all the joints are fully extended, then the system becomes unstable. solution:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;damped least squares: $J^+=J^T(JJ^T+k^2I)^{-1}$ by imposing soft constraints&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;motion-capture--physically-based-character-animation&#34;&gt;Motion Capture &amp;amp; Physically-Based Character Animation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;motion capture
&lt;ul&gt;
&lt;li&gt;optical: reflective markers, 3D location computed by stereo vision; manually labelled first, tag again when occlusion, less intrusive, very accurate, capture motion + skin movement
&lt;ul&gt;
&lt;li&gt;joint center prediction: define coord system for each bone using markers, compute the trans matrix, $M_1v_1-M_2v_2=0$, solve with least squares&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;magnetic: location given by amplitude, no occlusion, no manual post-processing, less accurate (positios highly distorted, noise, no ~ devices), only 2-3m away&lt;/li&gt;
&lt;li&gt;inertial: measure $\Delta\omega$ (gyro sesnor) and $\Delta a$ to compute orientation and position, unlimited range, rapid accumulating errors, solution: periodically reset&lt;/li&gt;
&lt;li&gt;mechanical: need to additionally detect root location; video-based&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;physical: force (ma, coriolis, gravity) to body and torque to joints
&lt;ul&gt;
&lt;li&gt;f dynamics: input = force, output = a$\to$v, x (fall); id (punch)&lt;/li&gt;
&lt;li&gt;pd control: $-F=a(q-q_d)+c(q&amp;rsquo;+q&amp;rsquo;_d)$ for torque then switch (dance)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;forward--inverse-dynamics&#34;&gt;Forward / Inverse Dynamics&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;articulated bodies: force between joints, torque generated by motors at joints&lt;/li&gt;
&lt;li&gt;equation of motion $\tau=H\ddot{q}+C(q,\dot{q})+\tau_g$&lt;/li&gt;
&lt;li&gt;id: newton-euler - O(n), compute v, a from root to leaf with $q,\dot{q},\ddot{q}$,
&lt;ul&gt;
&lt;li&gt;eq of m $f_i^a=r\times F_{ext}+\tau=I\dot{\omega}+\omega\times I\omega$ with $\omega:=v$&lt;/li&gt;
&lt;li&gt;compute joint forces from leaf to root $f_{i+1}=f_i^a-f_i^{ext}+\sum_{j\in c(i)}f_j$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;fd: recursive n-e - O(n3), use id solver to compute $C(q,\dot{q})+\tau_g$ then H&lt;/li&gt;
&lt;li&gt;fd: articulated body inertia - O(n), compute $I^A,P$ from leaf to root, then $\ddot{q},a$ from root to leaves&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;motion-synthesis-by-optimization--editing&#34;&gt;Motion Synthesis by Optimization / Editing&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;optimization problems: high dimensionality, local extrema&lt;/li&gt;
&lt;li&gt;fd: hard to find good initial motion, need to keep balance; id: need good objective function&lt;/li&gt;
&lt;li&gt;motion warping (small, avoid obstacles): add offset to satisfy constraints, insert a keyframe&lt;/li&gt;
&lt;li&gt;motion editing by ik: ee trajectory, $\dot{q}=J^+\dot{x}+(I-J^+J)y$, null space term -&amp;gt; redundant dof &amp;amp; to do secondary tasks&lt;/li&gt;
&lt;li&gt;motion blending: to synchronize motions, dtw - similarity matrix by diff of postures, find shortest path from lb to rt; can also be used to search similar motion clips&lt;/li&gt;
&lt;li&gt;motion style editing: fourier analysis on 2 motions then interpolate&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;learning-human-motion&#34;&gt;Learning Human Motion&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;map between control signal to entire pose: radial basis fs, find coefficients given data pairs
&lt;ul&gt;
&lt;li&gt;gaussian processes for better interpolation in the middle&lt;/li&gt;
&lt;li&gt;solve linear system/optimize hyperparameters with knn is costly&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;matching: need to carefully select search feature, no learning happens&lt;/li&gt;
&lt;li&gt;dl: learn prior of motion data with temporal conv AE, temporal invariance&lt;/li&gt;
&lt;li&gt;ambiguity: e.g. foot contact, auto label with foot speed &amp;amp; height, use small nn to map trajectories to contact durations and freq&lt;/li&gt;
&lt;li&gt;motion editing: csp over hidden units&lt;/li&gt;
&lt;li&gt;whole process: disambiguation $\to$ motion synthesis $\to$ motion editing&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;learning-rt-controllers-from-mocap&#34;&gt;Learning RT Controllers from MoCap&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;classic: finite state machine, motion graphs $\to$ manual works, all motions in memory&lt;/li&gt;
&lt;li&gt;matching: search online, no pre-comp, still slower with large database $\to$ get stuck&lt;/li&gt;
&lt;li&gt;lstms: good control signal and architecture to avoid ambiguity in the future, motion smoothed out with avg poses, response to inputs can be slow&lt;/li&gt;
&lt;li&gt;phase-functioned nn: additional inputs for trajectory $\to$ remove ambiguity, produce transitions between diff styles&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;physics-based-animation&#34;&gt;Physics-based Animation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;$v=\dot{x}+\omega\times r$, $L=\sum_i m_ir_i\times(\omega\times r_i)=I\omega$, dL/dt=torque, $I=\sum mr^*r^{*T}=RI_0R$&lt;/li&gt;
&lt;li&gt;cons of mass-spring: depends on the set-up of the spring network, spring constants difficult to tune, volumetric effects cannot be captured directly (vol conservation, prevention of vol inversions)&lt;/li&gt;
&lt;li&gt;hyperelastic: independence of the strain energy on the prior deformation history.\&lt;/li&gt;
&lt;li&gt;deformation gradient F (Jacobian of $\phi$) $\to$ express strain energy, first PK stress tensor, &amp;hellip;&lt;/li&gt;
&lt;li&gt;constitutive model: math description of physical traits, eqs relate stimuli (deform) to material response (force stress)&lt;/li&gt;
&lt;li&gt;isotropic: resistance to deform same along all orientations $\iff \Psi(FQ)=\Psi(F)$&lt;/li&gt;
&lt;li&gt;rotational invariance $\iff \Psi(RF)=\Psi(F)$&lt;/li&gt;
&lt;li&gt;SVD$\to\Psi({F})=\Psi({U}{\Sigma}{V}^T)=\Psi({\Sigma})$ contains 3 singular values, write invariants in terms of them&lt;/li&gt;
&lt;li&gt;pros with $I$s: more intuitive about flavor and severity, assume rot inv, easy to compute derivatives, no tendency to collapse&lt;/li&gt;
&lt;li&gt;cons: SVD, chain rule to compute P from $\Psi$, derivatives non-linear/inverse mat cal $\to$ costly&lt;/li&gt;
&lt;li&gt;linear elasticity, St. Venant-Kirchhoff model, corotated linear elasticity, isotropic materials and invariants, and neohookean elasticity.&lt;/li&gt;
&lt;li&gt;TODO: implicit integration&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;crowd-simulation&#34;&gt;Crowd Simulation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;flocking: separation, alignment, cohesion, avoidance, with simple rules&lt;/li&gt;
&lt;li&gt;behavior model, a hand-tuned controller (grow if) + modules to synthesize behaviors $\uparrow$&lt;/li&gt;
&lt;li&gt;patch (shape+motion)-based, associate motions with objects, create scenes by building blocks&lt;/li&gt;
&lt;li&gt;pros: efficient data handling, decentralized $\implies$ scalable, crowd patches&lt;/li&gt;
&lt;li&gt;velocity obstacle; rvo: avg of v outside vo and current v - no oscillation, no globa comm needed between agents, can handle multiple agents (cal all rvo)&lt;/li&gt;
&lt;li&gt;continuum crowds: solve both path-plan and coll-avoid
&lt;ul&gt;
&lt;li&gt;compute potential field (given other avatars, obstacles and the goal), determine movement, update field&lt;/li&gt;
&lt;li&gt;group by the inputs, efficient if few groups&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;supervised learning: track crowd behaviors in video with cv techniques $\to$ s-a pairs
&lt;ul&gt;
&lt;li&gt;state: vel, neighbor~ formation (temporal?), intention (from avg motion), pivots&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;probabilistic model: find clusters of diff behaviors in neighbor~, regression within a sel cluster (s.t. motion does not switch often)&lt;/li&gt;
&lt;li&gt;high-level: first fsm then model; follow trajectory: blend motion in diff curvatures&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;skinning&#34;&gt;Skinning&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;linear blend skinning: a vertex belongs to multiple bones $v=\sum_i w_iM_i&amp;rsquo;M_i^{-1}v_g$&lt;/li&gt;
&lt;li&gt;dual quaternions used to blend rigid trans, without volume loss at extreme joint angles&lt;/li&gt;
&lt;li&gt;rot: $q=C\frac{\theta}{2}+nS\frac{\theta}{2}, v&amp;rsquo;=qvq^*$; dual: $\hat{a}=a_0+\epsilon a_{\epsilon}$ with $\epsilon^2=0$&lt;/li&gt;
&lt;li&gt;a0 rot; ae trans: $1+\frac{\epsilon}{2}(ai+bj+ck)$; coord: $1+\epsilon(v_0i+v_1j+v_2k)$&lt;/li&gt;
&lt;li&gt;matrix for each bone by fk, convert to dual, normalize, cal global pos $\hat{q}\hat{v}\bar{\hat{q}^*}$&lt;/li&gt;
&lt;li&gt;anatomical: muscles contract when joints bent, dist decreases, vol pump up, skin deformed&lt;/li&gt;
&lt;li&gt;data-driven: template model + body shape + pose offsets&lt;/li&gt;
&lt;li&gt;body = 21,000D point $\to$ subtract mean and do pca&lt;/li&gt;
&lt;li&gt;rest pose v T 3N, joint loc J 3K, blend weights W NxK, pose params $\theta$ 3K; offset to rest pose then LBS&lt;/li&gt;
&lt;li&gt;smpl: $T(\theta)=T+B_p(\theta),B_p(\theta)=\sum_i f_i(\theta)P_i$ , Pi = vec of displacements in actual poses&lt;/li&gt;
&lt;li&gt;$f(\theta)$ linear in rot mat but non-linear in pose; $M(\theta,\beta;T,S,P,W,J)$&lt;/li&gt;
&lt;li&gt;trained to min surface reconst error&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;facial-animation&#34;&gt;Facial Animation&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;geometry and texture data, fit a generic face mesh into the range data using feature points&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;skin, fat, muscles: mass-spring, need to preserve volume - push node upwards&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;animation: with anatomical model, muscles activated to overlap markers&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cons of musculoskeletal model: quality depends on model (muscle details, soft materials, muscle activation); below: expression cloning, cal corr with RBF&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wwwCielwww.github.io/p/comp3360/express-clone.png&#34;
	width=&#34;638&#34;
	height=&#34;466&#34;
	srcset=&#34;https://wwwCielwww.github.io/p/comp3360/express-clone_hu13b24fb2d0bebbb768444094c4810f7b_64474_480x0_resize_box_3.png 480w, https://wwwCielwww.github.io/p/comp3360/express-clone_hu13b24fb2d0bebbb768444094c4810f7b_64474_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;136&#34;
		data-flex-basis=&#34;328px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;amend motion vectors: rot adjusted by diff of normal vectors between src and tgt; mag scaled by local size variation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;deformation transfer: mesh-based, can do non-rigid deform; first cal deform for every src triangle, then cal mapping from src to tgt, apply deform to tgt triangles&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;this leads to holes in result mesh as too many dof; solve by preserve consistency: $\min\sum_j \norm{S_{s_j}-T_{t_j}}^2$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;photometric cap: find 3D location with stereo vision, normal vectors added as details&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;blendshapes: face ik - $\min\sum(c_f-c&amp;rsquo;&lt;em&gt;f)^2$ subject to $\sum c_fs&lt;/em&gt;{l,f}=p_l$ and $\sum c_f$=1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;impossible hard constraints $\to$ unstable results; sol: change $p_l$ to soft and min diff&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;local control to create more, e.g. asymmetric expressions not from symmetric&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;digital emily: take img under diff lighting, create reflectance model $\to$ polarization, reconstruct 3D geometry, produce facial rig, create animation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;diffuse (directional, no dep on cam angle) $I_pk_d\cos\theta$+ specular (highlights, no dep on color) $I_pk_s(\cos\alpha)^n$ reflection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;parallel polarizer passes specular + part diffuse; cross passes part diffuse&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
